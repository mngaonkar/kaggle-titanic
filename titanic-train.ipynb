{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "import sagemaker\n",
    "from sagemaker.xgboost import XGBoost\n",
    "from sagemaker.mxnet import MXNet\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "print(train_data.head())\n",
    "\n",
    "# print missing data\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "def plot_bar_graph(train_data, feature):\n",
    "    survived = train_data[train_data['Survived'] == 1][feature].value_counts()\n",
    "    dead = train_data[train_data['Survived'] == 0][feature].value_counts()\n",
    "    df = pd.DataFrame([survived, dead])\n",
    "    df.index = ['Survived', 'Dead']\n",
    "    df.plot(kind='bar', stacked=False, figsize=(10, 5))\n",
    "    \n",
    "def plot_feature_count(train_data, feature):\n",
    "    count = train_data[feature].value_counts()\n",
    "    # mean = train_data[feature].mean()\n",
    "    # print(\"mean = \", mean)\n",
    "    print(count)\n",
    "    df = pd.DataFrame([count])\n",
    "    df.index = [feature]\n",
    "    df.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Cabin  Embarked\n",
      "0          0       3    1   22      1      0     7      2         2\n",
      "1          1       1    0   38      1      0    71      2         0\n",
      "2          1       3    0   26      0      0     7      2         2\n",
      "3          1       1    0   35      1      0    53      2         2\n",
      "4          0       3    1   35      0      0     8      2         2\n",
      "..       ...     ...  ...  ...    ...    ...   ...    ...       ...\n",
      "76         0       3    1   29      0      0     7      2         2\n",
      "77         0       3    1   29      0      0     8      2         2\n",
      "78         1       2    1    0      0      2    29      2         2\n",
      "79         1       3    0   30      0      0    12      2         2\n",
      "80         0       3    1   22      0      0     9      2         2\n",
      "\n",
      "[80 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# move target label to first column, requirement of sagemaker XGBoost\n",
    "survived = train_data['Survived']\n",
    "train_data.drop(labels=['Survived'], axis=1, inplace=True)\n",
    "\n",
    "# remove irrelevant feature data\n",
    "train_data.drop(labels=['Name', 'PassengerId', 'Ticket'], axis=1, inplace=True)\n",
    "\n",
    "# insert target as first column\n",
    "train_data.insert(0, 'Survived', survived)\n",
    "\n",
    "# drop NaN rows for embarked\n",
    "train_data = train_data.dropna(subset=['Embarked'])\n",
    "\n",
    "# replace age NaN with mean age\n",
    "mean_age = train_data['Age'].mean()\n",
    "train_data['Age'] = train_data['Age'].fillna(mean_age)\n",
    "\n",
    "# extract cabin number\n",
    "train_data['Cabin'] = train_data['Cabin'].apply(lambda x : str(x)[0])\n",
    "\n",
    "# round age\n",
    "train_data['Age'] = train_data['Age'].apply(lambda x : int(x))\n",
    "\n",
    "# round fare\n",
    "train_data['Fare'] = train_data['Fare'].apply(lambda x : int(x))\n",
    "\n",
    "# plot_feature_count(train_data, 'Cabin')\n",
    "\n",
    "# replace cabin NaN with maximum 'S'\n",
    "train_data['Cabin'] = train_data['Cabin'].apply(lambda x : 'C' if x == 'n' else x)\n",
    "\n",
    "# plot_feature_count(train_data, 'Cabin')\n",
    "\n",
    "# label encode sex, cabin and embarked\n",
    "label_encoder = LabelEncoder()\n",
    "train_data['Sex'] = label_encoder.fit_transform(train_data['Sex'])\n",
    "train_data['Cabin'] = label_encoder.fit_transform(train_data['Cabin'])\n",
    "train_data['Embarked'] = label_encoder.fit_transform(train_data['Embarked'])\n",
    "\n",
    "bucket = 'sagemaker-us-east-1-756448110530'\n",
    "prefix = 'dataset'\n",
    "\n",
    "# plot_bar_graph('Cabin')\n",
    "\n",
    "print(train_data.head(80))\n",
    "\n",
    "train_xgboost, validation_xgboost, test_xgboost = np.split(train_data.sample(frac=1, random_state=1729), [int(0.7 * len(train_data)), int(0.9 * len(train_data))])\n",
    "\n",
    "# remove header as it is not required by XGBoost\n",
    "train_xgboost.to_csv('train_xgboost.csv', header=False, index=False)\n",
    "validation_xgboost.to_csv('validation_xgboost.csv', header=False, index=False)\n",
    "test_xgboost.to_csv('test_xgboost.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-756448110530/dataset/validation_xgboost.csv\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "train_path = sagemaker_session.upload_data(path='train_xgboost.csv', key_prefix='dataset')\n",
    "validation_path = sagemaker_session.upload_data(path='validation_xgboost.csv', key_prefix='dataset')\n",
    "test_path = sagemaker_session.upload_data(path='test.csv', key_prefix='test')\n",
    "print(validation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = get_image_uri(boto3.Session().region_name, 'xgboost', repo_version='0.90-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data=train_path, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=validation_path, content_type='csv')\n",
    "s3_input_test = sagemaker.s3_input(s3_data=test_path, content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(container,\n",
    "                                          'AmazonSageMaker-ExecutionRole-20190815T111389',\n",
    "                                          train_instance_count=1,\n",
    "                                          train_instance_type='ml.m4.2xlarge',\n",
    "                                          output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                          sagemaker_session=sagemaker_session,\n",
    "                                          train_use_spot_instances=True,\n",
    "                                          train_max_run=120,\n",
    "                                          train_max_wait=180,\n",
    "                                         )\n",
    "estimator.set_hyperparameters(eta=0.1,\n",
    "                             objective='binary:logistic',\n",
    "                             num_round=25,\n",
    "                             eval_metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "### estimator = XGBoost(entry_point='program.py',\n",
    "#                     role='AmazonSageMaker-ExecutionRole-20190815T111389',\n",
    "#                     train_instance_count=1,\n",
    "#                     train_instance_type='local',\n",
    "#                     framework_version='0.90-2',\n",
    "#                     hyperparameters = {\n",
    "#                         'max_depth':2,\n",
    "#                         'eta':0.2,\n",
    "#                         'objective':'binary:logistic',\n",
    "#                         'silent':0,\n",
    "#                         'num_round':100,\n",
    "#                         'eval_metric':'auc'\n",
    "#                     }\n",
    "#                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-01 20:42:24 Starting - Starting the training job...\n",
      "2020-04-01 20:42:26 Starting - Launching requested ML instances...\n",
      "2020-04-01 20:43:32 Starting - Preparing the instances for training......\n",
      "2020-04-01 20:44:40 Downloading - Downloading input data\n",
      "2020-04-01 20:44:40 Training - Downloading the training image...\n",
      "2020-04-01 20:45:16 Uploading - Uploading generated training model\n",
      "2020-04-01 20:45:16 Completed - Training job completed\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter eval_metric value accuracy to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[20:45:04] 622x8 matrix with 4976 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[20:45:04] 178x8 matrix with 1424 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 622 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 178 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.136656#011validation-error:0.168539#011train-accuracy:0.863344#011validation-accuracy:0.831461\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.130225#011validation-error:0.174157#011train-accuracy:0.869775#011validation-accuracy:0.825843\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.133441#011validation-error:0.174157#011train-accuracy:0.866559#011validation-accuracy:0.825843\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.130225#011validation-error:0.174157#011train-accuracy:0.869775#011validation-accuracy:0.825843\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.128617#011validation-error:0.174157#011train-accuracy:0.871383#011validation-accuracy:0.825843\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.12701#011validation-error:0.174157#011train-accuracy:0.87299#011validation-accuracy:0.825843\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.128617#011validation-error:0.174157#011train-accuracy:0.871383#011validation-accuracy:0.825843\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.128617#011validation-error:0.168539#011train-accuracy:0.871383#011validation-accuracy:0.831461\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.125402#011validation-error:0.157303#011train-accuracy:0.874598#011validation-accuracy:0.842697\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.120579#011validation-error:0.151685#011train-accuracy:0.879421#011validation-accuracy:0.848315\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.114148#011validation-error:0.157303#011train-accuracy:0.885852#011validation-accuracy:0.842697\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.114148#011validation-error:0.151685#011train-accuracy:0.885852#011validation-accuracy:0.848315\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.109325#011validation-error:0.146067#011train-accuracy:0.890675#011validation-accuracy:0.853933\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.104502#011validation-error:0.134831#011train-accuracy:0.895498#011validation-accuracy:0.865169\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.106109#011validation-error:0.134831#011train-accuracy:0.893891#011validation-accuracy:0.865169\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.104502#011validation-error:0.129213#011train-accuracy:0.895498#011validation-accuracy:0.870787\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.104502#011validation-error:0.129213#011train-accuracy:0.895498#011validation-accuracy:0.870787\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.102894#011validation-error:0.129213#011train-accuracy:0.897106#011validation-accuracy:0.870787\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.102894#011validation-error:0.134831#011train-accuracy:0.897106#011validation-accuracy:0.865169\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.102894#011validation-error:0.129213#011train-accuracy:0.897106#011validation-accuracy:0.870787\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.104502#011validation-error:0.140449#011train-accuracy:0.895498#011validation-accuracy:0.859551\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.102894#011validation-error:0.134831#011train-accuracy:0.897106#011validation-accuracy:0.865169\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.102894#011validation-error:0.151685#011train-accuracy:0.897106#011validation-accuracy:0.848315\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.101286#011validation-error:0.162921#011train-accuracy:0.898714#011validation-accuracy:0.837079\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.101286#011validation-error:0.157303#011train-accuracy:0.898714#011validation-accuracy:0.842697\u001b[0m\n",
      "Training seconds: 47\n",
      "Billable seconds: 17\n",
      "Managed Spot Training savings: 63.8%\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\n",
    "    'train': s3_input_train,\n",
    "    'validation': s3_input_validation\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
